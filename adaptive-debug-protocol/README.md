# Adaptive Debug Protocol

# The Claude Code Debug Amplifier: When Claude Hits a Wall

A military-grade debugging system that transforms AI into a relentless problem-solving machine using OODA loops, escalating thinking levels, and systematic hypothesis testing.

# ðŸŽ¯ Overview

The Adaptive Debug Protocol is a structured debugging methodology that forces breakthrough thinking when traditional approaches fail. It's designed to break AI out of failed solution loops by:

* **Forcing root cause analysis** through systematic OODA loops
* **Escalating cognitive intensity** (think â†’ megathink â†’ ultrathink)
* **Building on failures** \- each failed hypothesis is a successful elimination
* **Creating comprehensive documentation** via detailed debug logs
* **Preventing endless loops** with a 4-iteration limit before escalation

# ðŸ”„ The OODA Loop Process

The protocol operates through iterative OODA (Observe, Orient, Decide, Act) loops, a decision-making framework originally developed for military strategy, now adapted for systematic debugging:

# Loop Structure

1. **OBSERVE** \- Gather raw data without filtering
2. **ORIENT** \- Analyze data using appropriate frameworks
3. **DECIDE** \- Form testable hypothesis
4. **ACT** \- Execute experiment and measure
5. **CHECK & RE-LOOP** \- Evaluate results and determine next action

# Automatic Progression

* **Loop 1**: Standard thinking (4K tokens) - Initial investigation
* **Loop 2**: Megathink (10K tokens) - Deeper pattern analysis
* **Loop 3-4**: Ultrathink (31.9K tokens) - Comprehensive system analysis
* **After Loop 4**: Automatic escalation with full documentation

# ðŸ“Š Problem Classification System

The protocol adapts its approach based on bug type:

|Bug Type|Primary Frameworks|Thinking Level|
|:-|:-|:-|
|**ðŸ’­ Logic Error**|5 Whys, Differential Analysis, Rubber Duck|Standard (4K)|
|**ðŸ’¾ State Error**|Timeline Analysis, State Comparison, Systems Thinking|Megathink (10K)|
|**ðŸ”Œ Integration Error**|Contract Testing, Systems Thinking, Timeline Analysis|Megathink (10K)|
|**âš¡ Performance Error**|Profiling Analysis, Bottleneck Analysis|Standard (4K)|
|**âš™ï¸ Configuration Error**|Differential Analysis, Dependency Graph|Standard (4K)|
|**â“ Complete Mystery**|Ishikawa Diagram, First Principles, Systems Thinking|Ultrathink (31.9K)|

# ðŸ“ The Debug Log File

One of the most powerful features is the automatic creation of a `debug_loop.md` file that provides:

# Real-Time Documentation

    # Debug Session - [Timestamp]
    ## Problem: [Issue description]
    
    ## Loop 1 - [Timestamp]
    **Goal:** [Specific objective for this iteration]
    **Problem Type:** [Classification]
    
    ### OBSERVE
    [Data collected and observations]
    
    ### ORIENT  
    [Analysis method and findings]
    
    ### DECIDE
    [Hypothesis and test plan]
    
    ### ACT
    [Test executed and results]
    
    ### LOOP SUMMARY
    [Outcome and next steps]

# Benefits of the Log File

* **Knowledge Persistence**: Every debugging session becomes reusable knowledge
* **Team Collaboration**: Share detailed debugging process with teammates
* **Post-Mortem Analysis**: Review what worked and what didn't
* **Learning Resource**: Build a library of solved problems and approaches
* **Audit Trail**: Complete record of troubleshooting steps for compliance

# ðŸš€ Why It's Powerful

# 1. Prevents Solution Fixation

Traditional debugging often gets stuck repeating similar failed approaches. The protocol forces you to try fundamentally different strategies each loop.

# 2. Escalating Intelligence

As complexity increases, so does the AI's analytical depth:

* Simple bugs get quick, efficient solutions
* Complex mysteries trigger deep, multi-faceted analysis
* Automatic escalation prevents giving up too early

# 3. Structured Yet Flexible

While following a rigorous framework, the protocol adapts to:

* Different bug types with specialized approaches
* Varying complexity levels
* Available information and tools

# 4. Failed Hypotheses = Progress

Every disproven hypothesis eliminates possibilities and builds understanding. The protocol treats failures as valuable data points, not setbacks.

# 5. Comprehensive Analysis Frameworks

Access to 13+ analytical frameworks ensures the right tool for the job:

* **5 Whys** for tracing causality
* **Ishikawa Diagrams** for systematic categorization
* **Timeline Analysis** for sequence-dependent bugs
* **Systems Thinking** for emergent behaviors
* And many more...

# ðŸŽ® How to Use

# Basic Usage

1. Share your bug description and what you've already tried
2. The protocol will classify the problem and begin Loop 1
3. Each loop will test a specific hypothesis
4. After 4 loops (max), you'll have either a solution or comprehensive documentation for escalation

# Advanced Usage

* **Provide context**: Include error messages, stack traces, and environment details
* **Share failures**: List what didn't work - this accelerates the process
* **Use the log**: Review the `debug_loop.md` file to understand the reasoning
* **Learn patterns**: Similar bugs often have similar solutions

# Best Practices

* Be specific about the problem behavior
* Include steps to reproduce
* Share relevant code snippets
* Document your environment (versions, configurations)
* Save the debug logs for future reference

# ðŸ§  Thinking Level Strategy

The protocol intelligently allocates cognitive resources:

# When Each Level Activates

* **Think (4K tokens)**: Initial exploration, simple logic errors
* **Megathink (10K tokens)**: Complex interactions, state problems
* **Ultrathink (31.9K tokens)**: System-wide issues, complete mysteries

# What Each Level Provides

* **Think**: Follow the symptoms, standard analysis
* **Megathink**: Pattern recognition, interaction analysis
* **Ultrathink**: Question every assumption, architectural analysis, emergent behavior detection

# ðŸ”§ Customization

The protocol can be adapted for:

* Specific technology stacks
* Domain-specific debugging (web, mobile, embedded)
* Team-specific workflows
* Custom logging formats

# ðŸŒŸ Key Differentiators

What sets this apart from standard debugging:

1. **Systematic Escalation**: Not just trying harder, but thinking differently
2. **Framework Selection**: Chooses the right analytical tool automatically
3. **Memory Through Documentation**: Every session contributes to collective knowledge
4. **Hypothesis-Driven**: Scientific method applied to code
5. **Anti-Patterns Avoided**: Built-in safeguards against common debugging mistakes

# ðŸ“š The Debug Loop Output

Each session produces a comprehensive artifact that includes:

* Problem classification and initial assessment
* Detailed record of each hypothesis tested
* Evidence gathered and patterns identified
* Final root cause (if found)
* Recommendations for prevention
* Complete timeline of the debugging process

# ðŸŽ¯ When to Use This Protocol

Perfect for:

* âœ… Bugs that have resisted initial attempts
* âœ… Complex multi-system issues
* âœ… Intermittent or hard-to-reproduce problems
* âœ… Performance mysteries
* âœ… "It works on my machine" scenarios
* âœ… Production issues needing systematic investigation

# ðŸš¦ Getting Started

Simply provide:

1. A description of the bug
2. What you've already tried (if anything)
3. Any error messages or logs
4. Environmental context

The protocol handles the rest, guiding you through a systematic investigation that either solves the problem or provides exceptional documentation for further escalation.

>**Note**: This protocol has been battle-tested on real debugging challenges and consistently delivers either solutions or actionable insights. It transforms the frustrating experience of debugging into a structured, progressive investigation that builds knowledge with each iteration.

*"Failed hypotheses are successful eliminations. Each loop builds understanding. Trust the process."*
